\documentclass[10pt]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{caption}
\usepackage{makecell}
\usepackage{multirow}
\usepackage{array}
\usepackage{esint}
\usepackage{adjustbox}
\usepackage{tabularht}
\usepackage{float}
\usepackage{hyperref}
\usepackage{nicefrac}    
\usepackage{microtype}
\usepackage{booktabs}
\usepackage{url}
\usepackage{dsfont}

\usetheme{sleep-states}
\usefonttheme[onlymath]{serif}



\title{\Huge{A Deep Learning approach to detect sleep states}}
\author{Armando Bringas, Alexis Guerrero}
\date{3rd January - 2024}




\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
  \frametitle{Introduction}
  \begin{block}{Kaggle competition}
    This paper presents a project proposal rooted in the practical application of a Kaggle competition,
aimed at addressing a challenge in pediatric health and neuroscience: the identification of sleep states
in children through wrist-worn accelerometer data.
  \end{block}
  \begin{block}{Project implications}
    The significance of this project lies in its potential to deepen our understanding of sleep and to provide
further insights into its importance. For instance, understanding how environmental factors influence
sleep, mood, and behavior can aid in formulating personalized strategies tailored to the unique needs
of each child.
  \end{block} 
\end{frame}

\begin{frame}
  \frametitle{Literature Review}
  \begin{block}{Models}
    \begin{itemize}
    \item Random Forest
    \item Residual Neural Network (RNN)
    \item Latent Class Analysis (LCA)
    \item Long Short-Term Memory (LSTM)
    \end{itemize}
  \end{block}
  \begin{block}{Data origin}
    \begin{itemize}
    \item Accelerometer data
    \item Actigraphy and sleep diaries
    \item Optical plethysmography
    \item Electrocardiography
    \item Electroencephalography
    \item Multi channel polysomnogram
      \begin{itemize}
      \item Electrooculography
      \item Electromyography
      \end{itemize}
    \end{itemize}
  \end{block} 
\end{frame}

\begin{frame}
  \frametitle{Dataset}
  \begin{block}{}
    Dataset consists of approximately 500 multi-day recordings from wrist-mounted accelerometers. The accelerometer data in the dataset was processed using R with the GGIR package \cite{Migueles2019GGIR}. The recordings are labeled with two event types: 'onset', indicating the start of sleep, and 'wakeup', marking its end. The primary objective is to identify these two events within the accelerometer data series, this primarily represents a binary classification task. 
    \begin{figure*}
        \centering
        \includegraphics[width=1\linewidth]{038441c925bb_anglez.png}
        \caption{Accelerometer training data. Plot of \texttt{step} againts \texttt{anglez} showing \texttt{event} state}
        \label{fig:accelerometerdata_series-038441c925bb_anglez}
    \end{figure*}
  \end{block} 
\end{frame}

\begin{frame}
  \frametitle{Model - Random Forest}
  \begin{block}{}
    The Random Forest model is initialized with a predetermined number of 100 estimators (n\textunderscore estimators)
and a minimum leaf sample size (min\textunderscore sample\textunderscore leaf) set to 300. These initial values are chosen for
the purpose of assessing the modelâ€™s efficiency and will be subject to subsequent adjustments based
on its performance. Given the substantial volume of data in this scenario, it is anticipated that the
minimum leaf sample size will remain unchanged, whereas the number of estimators will likely need
to be increased to optimize performance. An iteration process is set along the Random Forest model, changing the random\textunderscore state and n\textunderscore estimators values.
\begin{center}
  \begin{tikzpicture}
    \node at (0,0) (XRF) {$\mathcal{X}_{RF}$} ;
    \draw[thick, -stealth] (0.5,0) -- (1,0) ;
    \draw[thick] (1.5,-0.5) -- (4,-0.5) -- (4,0.5) -- (1.5,0.5) -- (1.5,-0.5) ;
    \node at (2.75,0.3) {\small{Random Forest}} ;
    \node at (2.75,-0.3) {\small{$i$th iteration}} ;
    \draw[thick, -stealth] (4.2,0) -- (4.8,0) ;
    \node at (7,0) (YRF) {\small{$\mathcal{Y}_{RF_i}(rs_i,Ne((i-1)[\bmod{3}]))$}} ;
  \end{tikzpicture}  
\end{center}
  \end{block} 
\end{frame}

\begin{frame}
  \frametitle{Model - LSTM}
  \begin{block}

        We are proposing a starting neural network architecture with the following blocks where consists of an LSTM layer of 64 units, ideal for processing sequences by capturing dependencies from prior inputs. This is followed by a Dense layer, the size of which matches the number of classification categories in your problem, in this case for our binary classification problem \(n_{\text{classes}} = 2\). The final component is a softmax activation function, applied to convert the output into a probability distribution across the predicted classes. 
        \begin{figure}[h]
          \centering
          \[
          \xrightarrow{\text{input}} \boxed{\text{LSTM} (64)} \rightarrow \boxed{\text{Dense} (n_{\text{classes}})} \xrightarrow{\text{softmax}}
          \]
          \caption{Neural Network for accelerometer data classification}
          \label{fig:neuralnetwork}
        \end{figure}
  \end{block} 
\end{frame}

\begin{frame}
  \frametitle{Evaluation Metrics}
  \begin{block}{Average Precision}
    \begin{gather*}
  \text{Inputs} \ \mathcal{X} = (x_1, \ldots, x_N)^\intercal \\
  \text{Outputs} \ \mathcal{Y} = (y_1, \ldots, y_N)^\intercal \\
  \text{Labels} \ \mathcal{W} = (w_1, \ldots, w_N)^\intercal 
    \end{gather*}

    \begin{equation*}
      AP = \frac{1}{N} \sum_{i=1}^{N}{\mathcal{C}(w_i,y_i)}
    \end{equation*}

    \[
    \mathcal{C}(w_i,y_i) =
    \begin{cases}
      1 \text{ if } w_i = y_i \forall i \in \mathds{N}, 1 \leq i \leq N\\
      0 \text{ if } w_i \neq y_i \forall i \in \mathds{N}, 1 \leq i \leq N
    \end{cases}
    \]
    \begin{equation*}
      APF(\mathcal{W}, \mathcal{Y}) = \frac{1}{N} (\omega_1, \ldots, \omega_N) (1, \ldots, 1)^\intercal
    \end{equation*}
  \end{block} 
\end{frame}

\begin{frame}
  \frametitle{Evaluation Metrics}
  \begin{block}{Specificity and Recall}
    \[
    \text{Score}(x) = 
    \begin{cases} 
      \text{TP} & \text{if }x \text{ matched and } x > \text{thresh.} \\
      \text{FP} & \text{if }x \text{ unmatched pred.} \\
      \text{FN} & \text{if }x \text{ unmatched truth} \\
      \text{TN} & \text{otherwise}
    \end{cases}
    \]
    \begin{equation*}
      \text{Specificity} = SPC = \frac{TP}{TP+FN} \hspace{5mm} \text{Recall} = SN = \frac{TN}{TN+FP}
    \end{equation*}
  \end{block}
  \begin{block}{Final evaluation}
    \begin{equation*}
      \text{Model evaluation } = \alpha APF + \beta SPC + \gamma SN 
    \end{equation*}
  \end{block}
\end{frame}


\begin{frame}
    \frametitle{Results}
    \begin{block}{}
        \begin{table}[h]
            \centering
            \caption{Model Comparison}
            \label{tab:model_comparison}
            \begin{tabular}{lccccc}
                \hline
                \textbf{Metric} & \textbf{Random Forest} & & \textbf{LSTM} & \\
                \cline{2-5}
                Accuracy & TBD & & 0.92 & \\
                Recall & TBD & & 0.90 & \\
                Specificity & TBD & & 0.97 & \\
                Average Precision & TBD & & 0.99 & \\
                Partial Evaluation & TBD & & 0.95 & \\
                \hline
            \end{tabular}
        \end{table}
    \end{block} 
\end{frame}

\begin{frame}
  \frametitle{Conclusion}
  \begin{block}{}
    Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum
  \end{block} 
\end{frame}


\begin{frame}
  \frametitle{Bibliography}
  \begin{block}{}
    {
        \small
        %%%%%%%%%%%%%
        \bibliographystyle{plainnat} % or another suitable style
        \bibliography{bibliography} % replace with your BibTeX file name
    }
  \end{block} 
\end{frame}

\end{document}
