{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score, make_scorer, accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import random as rm\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_filter_ids(file_path):\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file, checks for NaN values in 'step' column grouped by 'series_id',\n",
    "    and returns a list of 'series_id' values that do not contain NaNs.\n",
    "    \n",
    "    :param file_path: Path to the CSV file.\n",
    "    :return: List of series IDs without NaN values in the 'step' column.\n",
    "    \"\"\"\n",
    "    # Load data from CSV\n",
    "    train_events = pd.read_csv(file_path)\n",
    "\n",
    "    # Group by 'series_id' and check for NaN values in 'step' column\n",
    "    series_has_nan = train_events.groupby('series_id')['step'].apply(lambda x: x.isnull().any())\n",
    "\n",
    "    # Get list of series IDs that do not contain NaN values\n",
    "    train_ids = series_has_nan[~series_has_nan].index.tolist()\n",
    "\n",
    "    return train_ids\n",
    "\n",
    "# Usage example:\n",
    "file_path = \"../data/train_events.csv\"\n",
    "train_ids = load_data_and_filter_ids(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_light_series(series_ids):\n",
    "    \"\"\"\n",
    "    Fetches and processes a dataset for the given series IDs.\n",
    "\n",
    "    :param series_ids: List of series IDs to fetch.\n",
    "    :return: Processed DataFrame with added features.\n",
    "    \"\"\"\n",
    "    print(f'Fetching series IDs: {series_ids} \\n')\n",
    "    file_path = \"../data/zzzs-lightweight-training-dataset-target/Zzzs_train.parquet\"\n",
    "    multi_series = pd.read_parquet(file_path, filters=[('series_id', 'in', series_ids)])\n",
    "    multi_series = multi_series.astype({'series_id': 'category', 'step': 'int16', 'awake': 'int16'})\n",
    "    multi_series = add_features(multi_series)\n",
    "\n",
    "    return multi_series\n",
    "\n",
    "def add_features(df):\n",
    "    \"\"\"\n",
    "    Adds various features to the DataFrame.\n",
    "\n",
    "    :param df: DataFrame to which features are added.\n",
    "    :return: DataFrame with added features.\n",
    "    \"\"\"\n",
    "    df = add_time_features(df)\n",
    "    df = add_interaction_features(df)\n",
    "    df = add_rolling_features(df, periods=6)  # 1/2 minute\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_time_features(df):\n",
    "    \"\"\" Adds time-related features to the DataFrame. \"\"\"\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "def add_interaction_features(df):\n",
    "    \"\"\" Adds interaction features to the DataFrame. \"\"\"\n",
    "    df[\"anglez_times_enmo\"] = abs(df[\"anglez\"]) * df[\"enmo\"]\n",
    "    return df\n",
    "\n",
    "def add_rolling_features(df, periods):\n",
    "    \"\"\" Adds rolling features to the DataFrame. \"\"\"\n",
    "    # Define operations to be applied\n",
    "    operations = [\"mean\", \"min\", \"max\", \"std\"]\n",
    "    columns = [\"anglez\", \"enmo\"]\n",
    "\n",
    "    for column in columns:\n",
    "        for operation in operations:\n",
    "            df[f\"{column}_{operation}\"] = (\n",
    "                df[column].rolling(periods, center=True).agg(operation).bfill().ffill().astype('float32')\n",
    "            )\n",
    "\n",
    "        # Differential features\n",
    "        df[f\"{column}_diff\"] = (\n",
    "            df.groupby('series_id', observed=True)[column].diff(periods=periods).bfill()\n",
    "        )\n",
    "        df[f\"{column}_diff_rolling\"] = (\n",
    "            df[f\"{column}_diff\"].rolling(periods, center=True).mean().bfill().ffill().astype('float32')\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train_all = get_multi_light_series(train_ids[:35])\n",
    "print(f'memory usage: {train_all.memory_usage().sum() / 1024**2: .2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features_and_extract_target(df, feature_names, target_name):\n",
    "    \"\"\"\n",
    "    Scales the features of the dataset and extracts the target variable.\n",
    "\n",
    "    :param df: DataFrame containing the dataset.\n",
    "    :param feature_names: List of feature names to be scaled.\n",
    "    :param target_name: Name of the target variable.\n",
    "    :return: Tuple of scaled features array and target variable array.\n",
    "    \"\"\"\n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Scale the features\n",
    "    df_features_scaled = scaler.fit_transform(df[feature_names])\n",
    "\n",
    "    # Extract the target variable\n",
    "    df_target = df[target_name].values\n",
    "\n",
    "    return df_features_scaled, df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "features = [\"step\", \"hour\", \"dayofweek\", \"anglez_times_enmo\",\n",
    "            \"anglez\", \"anglez_diff\", \"anglez_mean\", \"anglez_min\", \"anglez_max\", \"anglez_std\", \"anglez_diff_rolling\",\n",
    "            \"enmo\", \"enmo_diff\", \"enmo_mean\", \"enmo_min\", \"enmo_max\", \"enmo_std\", \"enmo_diff_rolling\"]\n",
    "target = 'awake'\n",
    "\n",
    "# Assuming 'train_all' is your DataFrame\n",
    "df_train_X_scaled, df_train_y = scale_features_and_extract_target(train_all, features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_and_split(df_features, df_target, split_ratio=0.8, convert_to_tensor=True):\n",
    "    \"\"\"\n",
    "    Converts feature and target dataframes into PyTorch tensors and splits them into training and validation sets.\n",
    "\n",
    "    :param df_features: DataFrame or array containing the feature data.\n",
    "    :param df_target: DataFrame or array containing the target data.\n",
    "    :param split_ratio: Float representing the proportion of the dataset to include in the train split.\n",
    "    :param convert_to_tensor: Boolean \n",
    "    :return: Tuples of tensors (X_train, y_train), (X_val, y_val).\n",
    "    \"\"\"\n",
    "\n",
    "    if convert_to_tensor:\n",
    "        X = tensor(df_features, dtype=torch.float32)\n",
    "        y = tensor(df_target, dtype=torch.long)\n",
    "    else:\n",
    "        X, y = df_features, df_target\n",
    "\n",
    "    # Split the data\n",
    "    split_index = int(len(X) * split_ratio)\n",
    "    X_train, X_val = X[:split_index], X[split_index:]\n",
    "    y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val) = prepare_data_and_split(df_train_X_scaled, df_train_y)\n",
    "\n",
    "# Checking the shapes\n",
    "print(\"Train shapes (X, y):\", X_train.shape, y_train.shape)\n",
    "print(\"Validation shapes (X, y):\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ITERATIONS = 4\n",
    "RANDOM_STATE_MIN = 1\n",
    "RANDOM_STATE_MAX = 500\n",
    "N_ESTIMATORS_VALUES = [100, 200, 300]\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the model.\n",
    "\n",
    "    :param outputs: Model predictions.\n",
    "    :param labels: Ground truth labels.\n",
    "    :return: Accuracy as a float.\n",
    "    \"\"\"\n",
    "    predictions = outputs.argmax(dim=1)\n",
    "    correct = (predictions == labels)\n",
    "    return correct.float().mean()\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return specificity\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix.\n",
    "\n",
    "    :param y_true: True labels.\n",
    "    :param y_pred: Predicted labels.\n",
    "    :param class_names: List of class labels.\n",
    "    \"\"\"\n",
    "    # Generate confusion matrix using sklearn\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Calculate percentages\n",
    "    total = cm.sum()\n",
    "    tn_percentage = (cm[0, 0] / total) * 100\n",
    "    fp_percentage = (cm[0, 1] / total) * 100\n",
    "    fn_percentage = (cm[1, 0] / total) * 100\n",
    "    tp_percentage = (cm[1, 1] / total) * 100\n",
    "\n",
    "    tn_text = f\"{cm[0, 0]} ({tn_percentage:.2f}%)\"\n",
    "    fp_text = f\"{cm[0, 1]} ({fp_percentage:.2f}%)\"\n",
    "    fn_text = f\"{cm[1, 0]} ({fn_percentage:.2f}%)\"\n",
    "    tp_text = f\"{cm[1, 1]} ({tp_percentage:.2f}%)\"\n",
    "\n",
    "    # Print confusion matrix as a table with percentages\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"{'':<20} {'Predicted Negative':<20} {'Predicted Positive':<20}\")\n",
    "    print(f\"{'Actual Negative':<20} {tn_text:<20} {fp_text:<20}\")\n",
    "    print(f\"{'Actual Positive':<20} {fn_text:<20} {tp_text:<20}\")\n",
    "\n",
    "    # Plot confusion matrix using seaborn\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Purples', xticklabels=class_names, yticklabels=class_names, cbar=False) \n",
    "\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train, X_test, y_test, n_estimators_value, classes):\n",
    "    \"\"\"Trains and evaluates the performance of a random forest model\"\"\"\n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators_value,min_samples_leaf=300,random_state=42,n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_prob = rf_model.predict_proba(X_test)[:,1]\n",
    "    print(\"\"\"\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred, classes)\n",
    "\n",
    "    # Calculate and print evaluation scores\n",
    "    accuracy_value = accuracy_score(y_test, y_pred)\n",
    "    recall_value = recall_score(y_test, y_pred)\n",
    "    specificity_value = specificity_score(y_test, y_pred)\n",
    "    avg_precision_value = average_precision_score(y_test, y_prob)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(f'Accuracy: {accuracy_value:.2f}')\n",
    "    print(f'Recall: {recall_value:.2f}')\n",
    "    print(f'Specificity: {specificity_value:.2f}')\n",
    "    print(f'Average Precision Score: {avg_precision_value:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "    partial_eval = 0.4 * specificity_value + 0.3 * recall_value + 0.3 * avg_precision_value\n",
    "    print(f'Partial evaluation: {partial_eval:.2f}')\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    \n",
    "    return accuracy_value, recall_value, specificity_value, avg_precision_value, partial_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    random_state_value = None\n",
    "    results = []\n",
    "    labels = [\"Class 0\", \"Class 1\"]\n",
    "\n",
    "    for i in range(1, NUM_ITERATIONS + 1):\n",
    "        print(f'Iteration {i}')\n",
    "        if (i - 1) % len(N_ESTIMATORS_VALUES) == 0:\n",
    "            random_state_value = rm.randint(RANDOM_STATE_MIN, RANDOM_STATE_MAX)\n",
    "            print(\"Random State:\", random_state_value)\n",
    "            n_estimators_value = N_ESTIMATORS_VALUES[0]\n",
    "        else:\n",
    "            n_estimators_value = N_ESTIMATORS_VALUES[(i - 1) % len(N_ESTIMATORS_VALUES)]\n",
    "\n",
    "        print(\"N estimators:\", n_estimators_value)\n",
    "\n",
    "        iteration_results = train_random_forest(X_train, y_train, X_val, y_val, n_estimators_value, labels)\n",
    "        results.append(iteration_results)\n",
    "\n",
    "    avg_results = tuple(map(lambda x: sum(x) / len(results), zip(*results)))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(f'Accuracy: {avg_results[0]:.2f}')\n",
    "    print(f'Recall: {avg_results[1]:.2f}')\n",
    "    print(f'Specificity: {avg_results[2]:.2f}')\n",
    "    print(f'Average Precision Score: {avg_results[3]:.2f}')\n",
    "\n",
    "\n",
    "    final_eval = 0.4 * avg_results[2] + 0.3 * avg_results[1] + 0.3 * avg_results[3]\n",
    "    print(f'Final Evaluation: {final_eval:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
