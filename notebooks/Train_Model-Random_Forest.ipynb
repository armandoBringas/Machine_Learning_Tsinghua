{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import random as rm\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_filter_ids(file_path):\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file, checks for NaN values in 'step' column grouped by 'series_id',\n",
    "    and returns a list of 'series_id' values that do not contain NaNs.\n",
    "    \n",
    "    :param file_path: Path to the CSV file.\n",
    "    :return: List of series IDs without NaN values in the 'step' column.\n",
    "    \"\"\"\n",
    "    # Load data from CSV\n",
    "    train_events = pd.read_csv(file_path)\n",
    "\n",
    "    # Group by 'series_id' and check for NaN values in 'step' column\n",
    "    series_has_nan = train_events.groupby('series_id')['step'].apply(lambda x: x.isnull().any())\n",
    "\n",
    "    # Get list of series IDs that do not contain NaN values\n",
    "    train_ids = series_has_nan[~series_has_nan].index.tolist()\n",
    "\n",
    "    return train_ids\n",
    "\n",
    "# Usage example:\n",
    "file_path = \"../data/train_events.csv\"\n",
    "train_ids = load_data_and_filter_ids(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_light_series(series_ids):\n",
    "    \"\"\"\n",
    "    Fetches and processes a dataset for the given series IDs.\n",
    "\n",
    "    :param series_ids: List of series IDs to fetch.\n",
    "    :return: Processed DataFrame with added features.\n",
    "    \"\"\"\n",
    "    print(f'Fetching series IDs: {series_ids} \\n')\n",
    "    file_path = \"../data/zzzs-lightweight-training-dataset-target/Zzzs_train.parquet\"\n",
    "    multi_series = pd.read_parquet(file_path, filters=[('series_id', 'in', series_ids)])\n",
    "    multi_series = multi_series.astype({'series_id': 'category', 'step': 'int16', 'awake': 'int16'})\n",
    "    multi_series = add_features(multi_series)\n",
    "\n",
    "    return multi_series\n",
    "\n",
    "def add_features(df):\n",
    "    \"\"\"\n",
    "    Adds various features to the DataFrame.\n",
    "\n",
    "    :param df: DataFrame to which features are added.\n",
    "    :return: DataFrame with added features.\n",
    "    \"\"\"\n",
    "    df = add_time_features(df)\n",
    "    df = add_interaction_features(df)\n",
    "    df = add_rolling_features(df, periods=6)  # 1/2 minute\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_time_features(df):\n",
    "    \"\"\" Adds time-related features to the DataFrame. \"\"\"\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "def add_interaction_features(df):\n",
    "    \"\"\" Adds interaction features to the DataFrame. \"\"\"\n",
    "    df[\"anglez_times_enmo\"] = abs(df[\"anglez\"]) * df[\"enmo\"]\n",
    "    return df\n",
    "\n",
    "def add_rolling_features(df, periods):\n",
    "    \"\"\" Adds rolling features to the DataFrame. \"\"\"\n",
    "    # Define operations to be applied\n",
    "    operations = [\"mean\", \"min\", \"max\", \"std\"]\n",
    "    columns = [\"anglez\", \"enmo\"]\n",
    "\n",
    "    for column in columns:\n",
    "        for operation in operations:\n",
    "            df[f\"{column}_{operation}\"] = (\n",
    "                df[column].rolling(periods, center=True).agg(operation).bfill().ffill().astype('float32')\n",
    "            )\n",
    "\n",
    "        # Differential features\n",
    "        df[f\"{column}_diff\"] = (\n",
    "            df.groupby('series_id', observed=True)[column].diff(periods=periods).bfill()\n",
    "        )\n",
    "        df[f\"{column}_diff_rolling\"] = (\n",
    "            df[f\"{column}_diff\"].rolling(periods, center=True).mean().bfill().ffill().astype('float32')\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching series IDs: ['08db4255286f', '0a96f4993bd7', '0cfc06c129cc', '1087d7b0ff2e', '10f8bc1f7b07', '18b61dd5aae8', '29c75c018220', '31011ade7c0a', '3452b878e596', '349c5562ee2c', '3664fe9233f9', '483d6545417f', '55a47ff9dc8a', '5acc9d63b5fd', '5f94bb3e1bed', '655f19eabf1e', '67f5fc60e494', '72bbd1ac3edf', '76237b9406d5', '7822ee8fe3ec', '89bd631d1769', '8e32047cbc1f', '939932f1822d', '9ee455e4770d', 'a596ad0b82aa', 'a9a2f7fac455', 'a9e5f5314bcb', 'af91d9a50547', 'b364205aba43', 'c535634d7dcd', 'c6788e579967', 'c68260cc9e8f', 'ca730dbf521d', 'd150801f3145', 'd25e479ecbb7'] \n",
      "\n",
      "CPU times: total: 1min 34s\n",
      "Wall time: 2min 15s\n",
      "memory usage:  968.23 MB\n"
     ]
    }
   ],
   "source": [
    "%time train_all = get_multi_light_series(train_ids[:35])\n",
    "print(f'memory usage: {train_all.memory_usage().sum() / 1024**2: .2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>anglez</th>\n",
       "      <th>enmo</th>\n",
       "      <th>awake</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>anglez_times_enmo</th>\n",
       "      <th>anglez_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>anglez_max</th>\n",
       "      <th>anglez_std</th>\n",
       "      <th>anglez_diff</th>\n",
       "      <th>anglez_diff_rolling</th>\n",
       "      <th>enmo_mean</th>\n",
       "      <th>enmo_min</th>\n",
       "      <th>enmo_max</th>\n",
       "      <th>enmo_std</th>\n",
       "      <th>enmo_diff</th>\n",
       "      <th>enmo_diff_rolling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08db4255286f</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-05 14:00:00+00:00</td>\n",
       "      <td>-30.845301</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.378785</td>\n",
       "      <td>-33.749619</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.845301</td>\n",
       "      <td>1.463509</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08db4255286f</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-05 14:00:05+00:00</td>\n",
       "      <td>-34.181801</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.514254</td>\n",
       "      <td>-33.749619</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.845301</td>\n",
       "      <td>1.463509</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08db4255286f</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-05 14:00:10+00:00</td>\n",
       "      <td>-33.877102</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.636264</td>\n",
       "      <td>-33.749619</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.845301</td>\n",
       "      <td>1.463509</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08db4255286f</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-05 14:00:15+00:00</td>\n",
       "      <td>-34.282101</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2.331183</td>\n",
       "      <td>-33.749619</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.845301</td>\n",
       "      <td>1.463509</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.055533</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.0626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08db4255286f</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-05 14:00:20+00:00</td>\n",
       "      <td>-34.385799</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2.640830</td>\n",
       "      <td>-33.694302</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.513399</td>\n",
       "      <td>1.595555</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.331902</td>\n",
       "      <td>0.065967</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.023801</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.0626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  step                 timestamp     anglez    enmo  awake  \\\n",
       "0  08db4255286f     0 2018-11-05 14:00:00+00:00 -30.845301  0.0447      1   \n",
       "1  08db4255286f     1 2018-11-05 14:00:05+00:00 -34.181801  0.0443      1   \n",
       "2  08db4255286f     2 2018-11-05 14:00:10+00:00 -33.877102  0.0483      1   \n",
       "3  08db4255286f     3 2018-11-05 14:00:15+00:00 -34.282101  0.0680      1   \n",
       "4  08db4255286f     4 2018-11-05 14:00:20+00:00 -34.385799  0.0768      1   \n",
       "\n",
       "   hour  dayofweek  anglez_times_enmo  anglez_mean  ...  anglez_max  \\\n",
       "0    14          0           1.378785   -33.749619  ...  -30.845301   \n",
       "1    14          0           1.514254   -33.749619  ...  -30.845301   \n",
       "2    14          0           1.636264   -33.749619  ...  -30.845301   \n",
       "3    14          0           2.331183   -33.749619  ...  -30.845301   \n",
       "4    14          0           2.640830   -33.694302  ...  -30.513399   \n",
       "\n",
       "   anglez_std  anglez_diff  anglez_diff_rolling  enmo_mean  enmo_min  \\\n",
       "0    1.463509     0.331902             0.331902   0.055533    0.0443   \n",
       "1    1.463509     0.331902             0.331902   0.055533    0.0443   \n",
       "2    1.463509     0.331902             0.331902   0.055533    0.0443   \n",
       "3    1.463509     0.331902             0.331902   0.055533    0.0443   \n",
       "4    1.595555     0.331902             0.331902   0.065967    0.0443   \n",
       "\n",
       "   enmo_max  enmo_std  enmo_diff  enmo_diff_rolling  \n",
       "0    0.0768  0.013588     0.0626             0.0626  \n",
       "1    0.0768  0.013588     0.0626             0.0626  \n",
       "2    0.0768  0.013588     0.0626             0.0626  \n",
       "3    0.0768  0.013588     0.0626             0.0626  \n",
       "4    0.1073  0.023801     0.0626             0.0626  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features_and_extract_target(df, feature_names, target_name):\n",
    "    \"\"\"\n",
    "    Scales the features of the dataset and extracts the target variable.\n",
    "\n",
    "    :param df: DataFrame containing the dataset.\n",
    "    :param feature_names: List of feature names to be scaled.\n",
    "    :param target_name: Name of the target variable.\n",
    "    :return: Tuple of scaled features array and target variable array.\n",
    "    \"\"\"\n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Scale the features\n",
    "    df_features_scaled = scaler.fit_transform(df[feature_names])\n",
    "\n",
    "    # Extract the target variable\n",
    "    df_target = df[target_name].values\n",
    "\n",
    "    return df_features_scaled, df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "features = [\"step\", \"hour\", \"dayofweek\", \"anglez_times_enmo\",\n",
    "            \"anglez\", \"anglez_diff\", \"anglez_mean\", \"anglez_min\", \"anglez_max\", \"anglez_std\", \"anglez_diff_rolling\",\n",
    "            \"enmo\", \"enmo_diff\", \"enmo_mean\", \"enmo_min\", \"enmo_max\", \"enmo_std\", \"enmo_diff_rolling\"]\n",
    "target = 'awake'\n",
    "\n",
    "# Assuming 'train_all' is your DataFrame\n",
    "df_train_X_scaled, df_train_y = scale_features_and_extract_target(train_all, features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_and_split(df_features, df_target, split_ratio=0.8, convert_to_tensor=True):\n",
    "    \"\"\"\n",
    "    Converts feature and target dataframes into PyTorch tensors and splits them into training and validation sets.\n",
    "\n",
    "    :param df_features: DataFrame or array containing the feature data.\n",
    "    :param df_target: DataFrame or array containing the target data.\n",
    "    :param split_ratio: Float representing the proportion of the dataset to include in the train split.\n",
    "    :param convert_to_tensor: Boolean \n",
    "    :return: Tuples of tensors (X_train, y_train), (X_val, y_val).\n",
    "    \"\"\"\n",
    "\n",
    "    if convert_to_tensor:\n",
    "        X = tensor(df_features, dtype=torch.float32)\n",
    "        y = tensor(df_target, dtype=torch.long)\n",
    "    else:\n",
    "        X, y = df_features, df_target\n",
    "\n",
    "    # Split the data\n",
    "    split_index = int(len(X) * split_ratio)\n",
    "    X_train, X_val = X[:split_index], X[split_index:]\n",
    "    y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes (X, y): torch.Size([10027296, 18]) torch.Size([10027296])\n",
      "Validation shapes (X, y): torch.Size([2506824, 18]) torch.Size([2506824])\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_val, y_val) = prepare_data_and_split(df_train_X_scaled, df_train_y)\n",
    "\n",
    "# Checking the shapes\n",
    "print(\"Train shapes (X, y):\", X_train.shape, y_train.shape)\n",
    "print(\"Validation shapes (X, y):\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_ITERATIONS = 15\n",
    "RANDOM_STATE_MIN = 1\n",
    "RANDOM_STATE_MAX = 500\n",
    "N_ESTIMATORS_VALUES = [100, 200, 300]\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the model.\n",
    "\n",
    "    :param outputs: Model predictions.\n",
    "    :param labels: Ground truth labels.\n",
    "    :return: Accuracy as a float.\n",
    "    \"\"\"\n",
    "    predictions = outputs.argmax(dim=1)\n",
    "    correct = (predictions == labels)\n",
    "    return correct.float().mean()\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return specificity\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    \"\"\"\n",
    "    Plot a confusion matrix.\n",
    "\n",
    "    :param y_true: True labels.\n",
    "    :param y_pred: Predicted labels.\n",
    "    :param class_names: List of class labels.\n",
    "    \"\"\"\n",
    "    # Generate confusion matrix using sklearn\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Calculate percentages\n",
    "    total = cm.sum()\n",
    "    tn_percentage = (cm[0, 0] / total) * 100\n",
    "    fp_percentage = (cm[0, 1] / total) * 100\n",
    "    fn_percentage = (cm[1, 0] / total) * 100\n",
    "    tp_percentage = (cm[1, 1] / total) * 100\n",
    "\n",
    "    tn_text = f\"{cm[0, 0]} ({tn_percentage:.2f}%)\"\n",
    "    fp_text = f\"{cm[0, 1]} ({fp_percentage:.2f}%)\"\n",
    "    fn_text = f\"{cm[1, 0]} ({fn_percentage:.2f}%)\"\n",
    "    tp_text = f\"{cm[1, 1]} ({tp_percentage:.2f}%)\"\n",
    "\n",
    "    # Print confusion matrix as a table with percentages\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"{'':<20} {'Predicted Negative':<20} {'Predicted Positive':<20}\")\n",
    "    print(f\"{'Actual Negative':<20} {tn_text:<20} {fp_text:<20}\")\n",
    "    print(f\"{'Actual Positive':<20} {fn_text:<20} {tp_text:<20}\")\n",
    "\n",
    "    # Plot confusion matrix using seaborn\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Purples', xticklabels=class_names, yticklabels=class_names, cbar=False) \n",
    "\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train, X_test, y_test, n_estimators_value, classes):\n",
    "    \"\"\"Trains and evaluates the performance of a random forest model\"\"\"\n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators_value,min_samples_leaf=300,random_state=42,n_jobs=-1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_prob = rf_model.predict_proba(X_test)[:,1]\n",
    "    print(\"\"\"\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y_test, y_pred, classes)\n",
    "\n",
    "    # Calculate and print evaluation scores\n",
    "    accuracy_value = accuracy_score(y_test, y_pred)\n",
    "    recall_value = recall_score(y_test, y_pred)\n",
    "    specificity_value = specificity_score(y_test, y_pred)\n",
    "    avg_precision_value = average_precision_score(y_test, y_prob)\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f'Accuracy: {accuracy_value:.2f}')\n",
    "    print(f'Recall: {recall_value:.2f}')\n",
    "    print(f'Specificity: {specificity_value:.2f}')\n",
    "    print(f'Average Precision Score: {avg_precision_value:.2f}')\n",
    "\n",
    "\n",
    "\n",
    "    partial_eval = 0.4 * specificity_value + 0.3 * recall_value + 0.3 * avg_precision_value\n",
    "    print(f'Partial evaluation: {partial_eval:.2f}')\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    \n",
    "    return accuracy_value, recall_value, specificity_value, avg_precision_value, partial_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    random_state_value = None\n",
    "    results = []\n",
    "    labels = [\"Class 0\", \"Class 1\"]\n",
    "\n",
    "    for i in range(1, NUM_ITERATIONS + 1):\n",
    "        print(f'Iteration {i}')\n",
    "        if (i - 1) % len(N_ESTIMATORS_VALUES) == 0:\n",
    "            random_state_value = rm.randint(RANDOM_STATE_MIN, RANDOM_STATE_MAX)\n",
    "            print(\"Random State:\", random_state_value)\n",
    "            n_estimators_value = N_ESTIMATORS_VALUES[0]\n",
    "        else:\n",
    "            n_estimators_value = N_ESTIMATORS_VALUES[(i - 1) % len(N_ESTIMATORS_VALUES)]\n",
    "\n",
    "        print(\"N estimators:\", n_estimators_value)\n",
    "\n",
    "        iteration_results = train_random_forest(X_train, y_train, X_val, y_val, n_estimators_value, labels)\n",
    "        results.append(iteration_results)\n",
    "\n",
    "        iteration_results = train_random_forest(X_train, y_train, X_val, y_val, n_estimators_value, labels)\n",
    "        results.append(iteration_results)\n",
    "\n",
    "    avg_results = tuple(map(lambda x: sum(x) / len(results), zip(*results)))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(f'Accuracy: {avg_results[0]:.2f}')\n",
    "    print(f'Recall: {avg_results[1]:.2f}')\n",
    "    print(f'Specificity: {avg_results[2]:.2f}')\n",
    "    print(f'Average Precision Score: {avg_results[3]:.2f}')\n",
    "\n",
    "    final_eval = 0.4 * avg_results[2] + 0.3 * avg_results[1] + 0.3 * avg_results[3]\n",
    "    print(f'Final Evaluation: {final_eval:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Random State: 199\n",
      "N estimators: 100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
